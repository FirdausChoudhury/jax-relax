{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelism Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from relax.import_essentials import *\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseStrategy:\n",
    "    \"\"\"Base class for mapping strategy.\"\"\"\n",
    "    \n",
    "    def __call__(\n",
    "        self, \n",
    "        fn: Callable, # Function to generate cf for a single input\n",
    "        xs: Array, # Input instances to be explained\n",
    "        pred_fn: Callable[[Array], Array],\n",
    "        y_targets: Array,\n",
    "        rng_keys: Iterable[jrand.PRNGKey],\n",
    "        **kwargs\n",
    "    ) -> Array: # Generated counterfactual explanations\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    __ALL__ = [\"__call__\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class IterativeStrategy(BaseStrategy):\n",
    "    \"\"\"Iterativly generate counterfactuals.\"\"\"\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        fn: Callable, # Function to generate cf for a single input\n",
    "        xs: Array, # Input instances to be explained\n",
    "        pred_fn: Callable[[Array], Array],\n",
    "        y_targets: Array,\n",
    "        rng_keys: Iterable[jrand.PRNGKey],\n",
    "        **kwargs\n",
    "    ) -> Array: # Generated counterfactual explanations\n",
    "        \n",
    "        assert xs.ndim == 2\n",
    "        cfs = jnp.stack([fn(xs[i], pred_fn=pred_fn, y_target=y_targets[i], rng_key=rng_keys[i], **kwargs) \n",
    "            for i in range(xs.shape[0])])\n",
    "        return cfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class VmapStrategy(BaseStrategy):\n",
    "    \"\"\"Generate counterfactuals via `jax.vmap`.\"\"\"\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        fn: Callable, # Function to generate cf for a single input\n",
    "        xs: Array, # Input instances to be explained\n",
    "        pred_fn: Callable[[Array], Array],\n",
    "        y_targets: Array,\n",
    "        rng_keys: Iterable[jrand.PRNGKey],\n",
    "        **kwargs\n",
    "    ) -> Array: # Generated counterfactual explanations\n",
    "        \n",
    "        def partial_fn(x, y_target, rng_key):\n",
    "            return fn(x, pred_fn=pred_fn, y_target=y_target, rng_key=rng_key, **kwargs)\n",
    "        \n",
    "        assert xs.ndim == 2\n",
    "        cfs = jax.vmap(partial_fn)(xs, y_targets, rng_keys)\n",
    "        return cfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _pad_divisible_X(\n",
    "    xs: Array,\n",
    "    n_devices: int\n",
    "):\n",
    "    \"\"\"Pad `X` to be divisible by `n_devices`.\"\"\"\n",
    "    if xs.shape[0] % n_devices != 0:\n",
    "        pad_size = n_devices - xs.shape[0] % n_devices\n",
    "        xs_pad = einops.repeat(\n",
    "            xs[-1:], \"n ... -> (pad n) ...\", pad=pad_size\n",
    "        )\n",
    "        xs = jnp.concatenate([xs, xs_pad])\n",
    "    X_padded = xs.reshape(n_devices, -1, *xs.shape[1:])\n",
    "    return X_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "xs = jnp.ones((5, 29))\n",
    "X_padded = _pad_divisible_X(xs, 2)\n",
    "assert X_padded.shape == (2, 3, 29)\n",
    "assert xs.sum() < X_padded.sum()\n",
    "\n",
    "xs = jax.nn.one_hot(jnp.arange(5), 29)\n",
    "X_padded = _pad_divisible_X(xs, 2)\n",
    "assert xs.shape == (5, 29)\n",
    "assert X_padded.shape == (2, 3, 29)\n",
    "assert np.array_equal(\n",
    "    X_padded.sum(-1), np.ones((2, 3))\n",
    ")\n",
    "\n",
    "xs = jrand.split(jrand.PRNGKey(0), 5)\n",
    "X_padded = _pad_divisible_X(xs, 2)\n",
    "assert X_padded.shape == (2, 3, 2)\n",
    "\n",
    "xs = jnp.ones((5, 29))\n",
    "X_padded = _pad_divisible_X(xs, 6)\n",
    "assert X_padded.shape == (6, 1, 29)\n",
    "\n",
    "xs = jnp.ones((5, 29))\n",
    "X_padded = _pad_divisible_X(xs, 1)\n",
    "assert X_padded.shape == (1, 5, 29)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PmapStrategy(BaseStrategy):\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_devices: int = None, # Number of devices. If None, use all available devices\n",
    "        strategy: str = 'auto', # Strategy to generate counterfactuals\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.strategy = strategy\n",
    "        self.n_devices = n_devices or jax.device_count()\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        fn: Callable, # Function to generate cf for a single input\n",
    "        xs: Array, # Input instances to be explained\n",
    "        pred_fn: Callable[[Array], Array],\n",
    "        y_targets: Array,\n",
    "        rng_keys: Iterable[jrand.PRNGKey],\n",
    "        **kwargs\n",
    "    ) -> Array: # Generated counterfactual explanations\n",
    "        \n",
    "        def partial_fn(x, y_target, rng_key, **kwargs):\n",
    "            return fn(x, pred_fn=pred_fn, y_target=y_target, rng_key=rng_key, **kwargs)\n",
    "\n",
    "        assert xs.ndim == 2\n",
    "        X_padded = _pad_divisible_X(xs, self.n_devices)\n",
    "        y_targets = _pad_divisible_X(y_targets, self.n_devices)\n",
    "        rng_keys = _pad_divisible_X(rng_keys, self.n_devices)\n",
    "        cfs = jax.pmap(jax.vmap(partial_fn))(X_padded, y_targets, rng_keys)\n",
    "        cfs = cfs.reshape(-1, *cfs.shape[2:])\n",
    "        cfs = cfs[:xs.shape[0]]\n",
    "        return cfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _pad_xs(\n",
    "    xs: Array, pad_size: int, batch_size: int\n",
    "):\n",
    "    \"\"\"Pad `X` to be divisible by `n_devices`.\"\"\"\n",
    "    xs_pad = einops.repeat(\n",
    "        xs[-1:], \"n ... -> (pad n) ...\", pad=pad_size\n",
    "    )\n",
    "    xs = jnp.concatenate([xs, xs_pad])\n",
    "    xs = einops.rearrange(xs, \"(b n) ... -> b n ...\", b=batch_size)\n",
    "    return xs\n",
    "\n",
    "def _batched_generation(\n",
    "    gs_fn: Callable, # Generation strategy function\n",
    "    cf_fn: Callable, # Function to generate cf for a single input\n",
    "    xs: Array, # Input instances to be explained\n",
    "    pred_fn: Callable[[Array], Array],\n",
    "    y_targets: Array,\n",
    "    rng_keys: Iterable[jrand.PRNGKey],\n",
    "    batch_size: int,\n",
    "    **kwargs\n",
    ") -> Array: # Generated counterfactual explanations\n",
    "    \"\"\"Batched  of counterfactuals.\"\"\"\n",
    "\n",
    "    def gs_fn_partial(state):\n",
    "        x, y_target, rng_key = state\n",
    "        return gs_fn(cf_fn, x, pred_fn, y_target, rng_key, **kwargs)\n",
    "    \n",
    "    assert xs.ndim == 2, f\"X must be a 2D array, got {xs.ndim}D array\"\n",
    "    x_shape = xs.shape\n",
    "    batch_size = min(batch_size, x_shape[0])\n",
    "    # pad X to be divisible by batch_size\n",
    "    pad_size = batch_size - (xs.shape[0] % batch_size)\n",
    "    xs = _pad_xs(xs, pad_size, batch_size)\n",
    "    y_targets = _pad_xs(y_targets, pad_size, batch_size)\n",
    "    rng_keys = _pad_xs(rng_keys, pad_size, batch_size)\n",
    "    # generate cfs via lax.map\n",
    "    cfs = lax.map(gs_fn_partial, (xs, y_targets, rng_keys))\n",
    "    # cfs = cfs.reshape(-1, *x_shape[1:])[:x_shape[0]]\n",
    "    cfs = einops.rearrange(cfs, \"n b ... k -> (n b) ... k\")\n",
    "    cfs = cfs[:x_shape[0]]\n",
    "    return cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BatchedVmapStrategy(BaseStrategy):\n",
    "    \"\"\"Auto-batching for generate counterfactuals via `jax.vmap`.\"\"\"\n",
    "    def __init__(self, batch_size: int):\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        fn: Callable, # Function to generate cf for a single input\n",
    "        xs: Array, # Input instances to be explained\n",
    "        pred_fn: Callable[[Array], Array],\n",
    "        y_targets: Array,\n",
    "        rng_keys: Iterable[jrand.PRNGKey],\n",
    "        **kwargs\n",
    "    ) -> Array: # Generated counterfactual explanations\n",
    "        vmap_g = VmapStrategy()    \n",
    "        cfs = _batched_generation(\n",
    "            vmap_g, fn, xs, pred_fn, y_targets, rng_keys, self.batch_size, **kwargs\n",
    "        )\n",
    "        return cfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BatchedPmapStrategy(BaseStrategy):\n",
    "    \"\"\"Auto-batching for generate counterfactuals via `jax.vmap`.\"\"\"\n",
    "    def __init__(self, batch_size: int, n_devices: int = None):\n",
    "        self.batch_size = batch_size\n",
    "        self.n_devices = n_devices\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        fn: Callable, # Function to generate cf for a single input\n",
    "        xs: Array, # Input instances to be explained\n",
    "        pred_fn: Callable[[Array], Array],\n",
    "        y_targets: Array,\n",
    "        rng_keys: Iterable[jrand.PRNGKey],\n",
    "        **kwargs\n",
    "    ) -> Array: # Generated counterfactual explanations\n",
    "        pmap_g = PmapStrategy(self.n_devices)\n",
    "        cfs = _batched_generation(\n",
    "            pmap_g, fn, xs, pred_fn, y_targets, rng_keys, self.batch_size, **kwargs\n",
    "        )\n",
    "        return cfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=8'\n",
    "\n",
    "w = jrand.normal(jrand.PRNGKey(0), (100, 100))\n",
    "xs = jrand.normal(jrand.PRNGKey(0), (1000, 100))\n",
    "\n",
    "@jit\n",
    "def pred_fn(x): return jnp.dot(x, w.T)\n",
    "\n",
    "def f(x, pred_fn=None, y_target=None, rng_key=None, **kwargs):\n",
    "    return pred_fn(x) + jrand.normal(rng_key, (1,))\n",
    "\n",
    "rng_keys = jrand.split(jrand.PRNGKey(0), 1000)\n",
    "y_targets = jnp.ones((1000, 100))\n",
    "\n",
    "iter_gen = IterativeStrategy()\n",
    "vmap_gen = VmapStrategy()\n",
    "pmap_gen = PmapStrategy()\n",
    "bvmap_gen = BatchedVmapStrategy(128)\n",
    "bpmap_gen = BatchedPmapStrategy(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_iter = iter_gen(f, xs, pred_fn=pred_fn, y_targets=y_targets, rng_keys=rng_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_vmap = vmap_gen(f, xs, pred_fn=pred_fn, y_targets=y_targets, rng_keys=rng_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_pmap = pmap_gen(f, xs, pred_fn=pred_fn, y_targets=y_targets, rng_keys=rng_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_bvmap = bvmap_gen(f, xs, pred_fn=pred_fn, y_targets=y_targets, rng_keys=rng_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# check when batch_size > X.shape[0]\n",
    "_bvmap_gen = BatchedVmapStrategy(1280)\n",
    "_cf_bvmap = _bvmap_gen(f, xs, pred_fn=pred_fn, y_targets=y_targets, rng_keys=rng_keys)\n",
    "assert jnp.allclose(cf_bvmap, _cf_bvmap, atol=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "cf_bpmap = bpmap_gen(f, xs, pred_fn=pred_fn, y_targets=y_targets, rng_keys=rng_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "assert jnp.allclose(cf_iter, cf_vmap, atol=1e-4)\n",
    "assert jnp.allclose(cf_iter, cf_bvmap, atol=1e-4)\n",
    "assert jnp.allclose(cf_iter, cf_pmap, atol=1e-4)\n",
    "assert jnp.allclose(cf_iter, cf_bpmap, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_mul(x, pred_fn=None, **kwargs):\n",
    "    cf = pred_fn(x)\n",
    "    return einops.repeat(cf, 'k -> c k', c=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_iter = iter_gen(f_mul, xs, pred_fn=pred_fn, y_targets=y_targets, rng_keys=rng_keys)\n",
    "cf_vmap = vmap_gen(f_mul, xs, pred_fn=pred_fn, y_targets=y_targets, rng_keys=rng_keys)\n",
    "cf_pmap = pmap_gen(f_mul, xs, pred_fn=pred_fn, y_targets=y_targets, rng_keys=rng_keys)\n",
    "cf_bvmap = bvmap_gen(f_mul, xs, pred_fn=pred_fn, y_targets=y_targets, rng_keys=rng_keys)\n",
    "cf_bpmap = bpmap_gen(f_mul, xs, pred_fn=pred_fn, y_targets=y_targets, rng_keys=rng_keys)\n",
    "\n",
    "assert jnp.allclose(cf_iter, cf_vmap, atol=1e-4)\n",
    "assert jnp.allclose(cf_iter, cf_bvmap, atol=1e-4)\n",
    "assert jnp.allclose(cf_iter, cf_pmap, atol=1e-4)\n",
    "assert jnp.allclose(cf_iter, cf_bpmap, atol=1e-4)\n",
    "assert cf_bvmap.shape == (xs.shape[0], 5, xs.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class StrategyFactory(object):\n",
    "    \"\"\"Factory class for Parallelism Strategy.\"\"\"\n",
    "\n",
    "    __strategy_map = {\n",
    "        'iter': IterativeStrategy(),\n",
    "        'vmap': VmapStrategy(),\n",
    "        'pmap': PmapStrategy(),\n",
    "    }\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        raise ValueError(\"This class should not be instantiated.\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_default_strategy() -> BaseStrategy:\n",
    "        \"\"\"Get default strategy.\"\"\"\n",
    "        return VmapStrategy()\n",
    "\n",
    "    @classmethod\n",
    "    def get_strategy(cls, strategy: str | BaseStrategy) -> BaseStrategy:\n",
    "        \"\"\"Get strategy.\"\"\"\n",
    "        if isinstance(strategy, BaseStrategy):\n",
    "            return strategy\n",
    "        elif isinstance(strategy, str) and strategy in cls.__strategy_map:\n",
    "            return cls.__strategy_map[strategy]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid strategy: {strategy}\")\n",
    "        \n",
    "    __ALL__ = [\"get_default_strategy\", \"get_strategy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = StrategyFactory.get_strategy('iter')\n",
    "vm = StrategyFactory.get_strategy('vmap')\n",
    "pm = StrategyFactory.get_strategy('pmap')\n",
    "default = StrategyFactory.get_default_strategy()\n",
    "cus = StrategyFactory.get_strategy(VmapStrategy())\n",
    "\n",
    "assert isinstance(it, IterativeStrategy)\n",
    "assert isinstance(vm, VmapStrategy)\n",
    "assert isinstance(pm, PmapStrategy)\n",
    "assert isinstance(default, VmapStrategy)\n",
    "assert isinstance(cus, VmapStrategy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
