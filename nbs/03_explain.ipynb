{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from relax.import_essentials import *\n",
    "from relax.data_module import DataModule, load_data\n",
    "from relax.base import *\n",
    "from relax.methods import *\n",
    "from relax.strategy import *\n",
    "from relax.ml_model import *\n",
    "from relax.utils import get_config, save_pytree, load_pytree\n",
    "import einops\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Explanation(DataModule):\n",
    "    \"\"\"Generated CF Explanations class. It inherits a `DataModule`.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfs: Array,  # Generated cf explanation of `xs` in `data`\n",
    "        pred_fn: Callable[[Array], Array],  # Predict function\n",
    "        data_module: DataModule = None,  # Data module\n",
    "        xs: Array = None,  # Input data\n",
    "        ys: Array = None,  # Target data\n",
    "        total_time: float = None,  # Total runtime\n",
    "        cf_name: str = \"CFModule\",  # CF method's name\n",
    "        data=None, # Deprecated argument\n",
    "    ):\n",
    "        if data is not None:\n",
    "            warnings.warn(\n",
    "                \"Argument `data` is deprecated. Use `data_module` instead.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "            data_module = data\n",
    "\n",
    "        if (xs is None or ys is None) and data_module is None:\n",
    "            raise ValueError(\n",
    "                \"Either `xs` and `ys` or `data_module` must be provided.\"\n",
    "            )\n",
    "        \n",
    "        if data_module is None:\n",
    "            data_module = DataModule.from_numpy(xs, ys, transformation='identity')\n",
    "        # assign attributes\n",
    "        # self.recourses = data_module.features.with_transformed_data(cfs)\n",
    "        self._cfs = cfs\n",
    "        self.pred_fn = pred_fn\n",
    "        self.total_time = total_time\n",
    "        self.cf_name = cf_name\n",
    "        \n",
    "        super().__init__(\n",
    "            features=data_module.features, \n",
    "            label=data_module.label,\n",
    "            config=data_module.config,\n",
    "            data=data_module.data,\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Explanation(data_name={self.data_name}, cf_name={self.cf_name}, \" \\\n",
    "               f\"total_time={self.total_time}, xs={self.xs}, ys={self.ys}, cfs={self.cfs})\"\n",
    "\n",
    "    def __getitem__(self, name: Literal['train', 'val', 'test']) -> Dict[str, Array]:\n",
    "        if name == 'train':\n",
    "            indices = self.train_indices\n",
    "        elif name in ['val', 'test']:\n",
    "            indices = self.test_indices\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown data name: {name}. Should be one of ['train', 'val', 'test']\")\n",
    "\n",
    "        if isinstance(indices, list):\n",
    "            indices = jnp.array(indices)\n",
    "        \n",
    "        return {\n",
    "            'xs': self.xs[indices],\n",
    "            'ys': self.ys[indices],\n",
    "            'cfs': self.cfs[indices],\n",
    "        }    \n",
    "\n",
    "    @property\n",
    "    def cfs(self) -> Array:\n",
    "        \"\"\"Return the counterfactuals in the shape of (n, c, k)\"\"\"\n",
    "        if self._cfs.ndim == 2:\n",
    "            return einops.rearrange(self._cfs, \"n d -> n () d\")\n",
    "        return self._cfs\n",
    "    \n",
    "    @property\n",
    "    def data_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    @property\n",
    "    def feature_indices(self):\n",
    "        return self.features.feature_indices\n",
    "    \n",
    "    @property\n",
    "    def features_and_indices(self):\n",
    "        return self.features.features_and_indices\n",
    "        \n",
    "    def save(self, path: str):\n",
    "        \"\"\"Save the explanation to a directory.\"\"\"\n",
    "        # create directories\n",
    "        dm_path = Path(path) / 'data'\n",
    "        exp_path = Path(path) / 'explanations'\n",
    "        exp_path.mkdir(parents=True, exist_ok=True)\n",
    "        # save data module and explanations\n",
    "        super().save(dm_path)        \n",
    "        save_pytree({\n",
    "            'cfs': self.cfs,\n",
    "            'total_time': self.total_time,\n",
    "            'cf_name': self.cf_name,\n",
    "        }, exp_path)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_from_path(cls, path: str, *, ml_module_path: str = None):\n",
    "        dm_path = Path(path) / 'data'\n",
    "        exp_path = Path(path) / 'explanations'\n",
    "        dm = DataModule.load_from_path(dm_path)\n",
    "        explanations = load_pytree(exp_path)\n",
    "        if ml_module_path is not None:\n",
    "            pred_fn = MLModule.load_from_path(ml_module_path).pred_fn\n",
    "        else:\n",
    "            warnings.warn(\"`ml_module_path` is not provided. Setting `pred_fn=None`.\")\n",
    "            pred_fn = None\n",
    "        return cls(\n",
    "            pred_fn=pred_fn,\n",
    "            data_module=dm,\n",
    "            **explanations\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fake_explanation(n_cfs: int=1):\n",
    "    dm = load_data('dummy')\n",
    "    ml_model = load_ml_module('dummy')\n",
    "    if n_cfs < 1: \n",
    "        raise ValueError(f'n_cfs must be greater than 0, but got n_cfs={n_cfs}.')\n",
    "    elif n_cfs == 1:\n",
    "        cfs = dm.xs\n",
    "    else:\n",
    "        # Allow for multiple counterfactuals\n",
    "        cfs = einops.repeat(dm.xs, \"n k -> n c k\", c=n_cfs)\n",
    "\n",
    "    return Explanation(\n",
    "        data_module=dm, cfs=cfs, pred_fn=ml_model.pred_fn, total_time=0.0, cf_name='dummy_method'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = fake_explanation(n_cfs=1)\n",
    "xs_shape = exp.xs.shape\n",
    "assert exp.cfs.shape == (xs_shape[0], 1, xs_shape[-1])\n",
    "train_exp = exp['train']\n",
    "val_exp = exp['val']\n",
    "test_exp = exp['test']\n",
    "assert jnp.concatenate(\n",
    "    [train_exp['cfs'], val_exp['cfs']], axis=0\n",
    ").shape == exp.cfs.shape\n",
    "assert test_exp['cfs'].shape == val_exp['cfs'].shape\n",
    "\n",
    "exp = fake_explanation(n_cfs=5)\n",
    "assert exp.cfs.shape == (xs_shape[0], 5, xs_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.save('tmp/exp/')\n",
    "exp = Explanation.load_from_path('tmp/exp/', \n",
    "    ml_module_path='relax-assets/dummy/model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prepare_pred_fn(\n",
    "    cf_module: CFModule,\n",
    "    data: DataModule,\n",
    "    pred_fn: Callable[[Array, ...], Array], # Predictive function. \n",
    "    pred_fn_args: Dict = None,\n",
    ") -> Callable[[Array], Array]: # Return predictive function with signature `(x: Array) -> Array`.\n",
    "    \"\"\"Prepare the predictive function for the CF module. \n",
    "    We will train the model if `pred_fn` is not provided and `cf_module` does not have `pred_fn`.\n",
    "    If `pred_fn` is found in `cf_module`, we will use it irrespective of `pred_fn` argument.\n",
    "    If `pred_fn` is provided, we will use it.\n",
    "    \"\"\"\n",
    "    # Train the model if `pred_fn` is not provided.\n",
    "    if not hasattr(cf_module, 'pred_fn') and pred_fn is None:\n",
    "        model = MLModule().train(data)\n",
    "        return model.pred_fn\n",
    "    # If `pred_fn` is detected in cf_module, \n",
    "    # use it irrespective of `pred_fn` argument.\n",
    "    elif hasattr(cf_module, 'pred_fn'):\n",
    "        return cf_module.pred_fn\n",
    "    # If `pred_fn` is provided, use it.\n",
    "    else:\n",
    "        if pred_fn_args is not None:\n",
    "            pred_fn = ft.partial(pred_fn, **pred_fn_args)\n",
    "        return pred_fn\n",
    "\n",
    "def prepare_cf_module(\n",
    "    cf_module: CFModule,\n",
    "    data_module: DataModule,\n",
    "    pred_fn: Callable[[Array], Array] = None,\n",
    "    train_config: Dict[str, Any] = None, \n",
    "):\n",
    "    \"\"\"Prepare the CF module. \n",
    "    It will hook up the data module, \n",
    "    and its apply functions via the `init_apply_fns` method\n",
    "    (e.g., `apply_constraints_fn` and `compute_reg_loss_fn`).\n",
    "    Next, it will train the model if `cf_module` is a `ParametricCFModule`.\n",
    "    Finally, it will call `before_generate_cf` method.\n",
    "    \"\"\"\n",
    "    cf_module.set_data_module(data_module)\n",
    "    cf_module.set_apply_constraints_fn(data_module.apply_constraints)\n",
    "    cf_module.set_compute_reg_loss_fn(data_module.compute_reg_loss)\n",
    "    train_config = train_config or {}\n",
    "    if isinstance(cf_module, ParametricCFModule):\n",
    "        if not cf_module.is_trained:\n",
    "            cf_module.train(data_module, pred_fn=pred_fn, **train_config)\n",
    "    cf_module.before_generate_cf()\n",
    "    return cf_module\n",
    "\n",
    "def prepare_rng_keys(\n",
    "    rng_key: jrand.PRNGKey,\n",
    "    n_instances: int,\n",
    "):\n",
    "    \"\"\"Prepare random number generator keys.\"\"\"\n",
    "    if rng_key is None:\n",
    "        rng_key = jrand.PRNGKey(get_config().global_seed)\n",
    "    rng_keys = jrand.split(rng_key, n_instances)\n",
    "    return rng_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_cf_explanations(\n",
    "    cf_module: CFModule, # CF Explanation Module\n",
    "    data: DataModule, # Data Module\n",
    "    pred_fn: Callable[[Array, ...], Array] = None, # Predictive function\n",
    "    strategy: str | BaseStrategy = None, # Parallelism Strategy for generating CFs. Default to `vmap`.\n",
    "    train_config: Dict[str, Any] = None, \n",
    "    pred_fn_args: dict = None, # auxiliary arguments for `pred_fn` \n",
    "    rng_key: jrand.PRNGKey = None, # Random number generator key\n",
    ") -> Explanation: # Return counterfactual explanations.\n",
    "    \"\"\"Generate CF explanations.\"\"\"\n",
    "\n",
    "    # Prepare `pred_fn`, `cf_module`, and `strategy`.\n",
    "    pred_fn = prepare_pred_fn(cf_module, data, pred_fn, pred_fn_args)\n",
    "    cf_module = prepare_cf_module(cf_module, data, pred_fn, train_config)\n",
    "    if strategy is None:\n",
    "        strategy = StrategyFactory.get_default_strategy()\n",
    "    strategy = StrategyFactory.get_strategy(strategy)\n",
    "    # n_instances\n",
    "    n_instances = data.xs.shape[0]\n",
    "    # Prepare random number generator keys.\n",
    "    rng_keys = prepare_rng_keys(rng_key, n_instances)\n",
    "    y_targets = 1 - pred_fn(data.xs)\n",
    "    \n",
    "    # Generate CF explanations.\n",
    "    start_time = time.time()\n",
    "    cfs = strategy(cf_module.generate_cf, data.xs, pred_fn, y_targets, rng_keys)\n",
    "    # cfs = jax.vmap(cf_module.generate_cf, in_axes=(0, None, 0, 0))(data.xs, pred_fn, y_targets, rng_keys)\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    # Return CF explanations.\n",
    "    return Explanation(\n",
    "        cf_name=cf_module.name,\n",
    "        data=data,\n",
    "        cfs=cfs,\n",
    "        total_time=total_time,\n",
    "        pred_fn=pred_fn,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = load_data(\"adult\")\n",
    "ml_model = load_ml_module(\"adult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6632bec477ef4a689db15bc0028f2cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5475/4129963786.py:17: DeprecationWarning: Argument `data` is deprecated. Use `data_module` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "exps = generate_cf_explanations(\n",
    "    VanillaCF(),\n",
    "    dm, ml_model.pred_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/birk/miniconda3/envs/dev/lib/python3.10/site-packages/relax/legacy/ckpt_manager.py:47: UserWarning: `monitor_metrics` is not specified in `CheckpointManager`. No checkpoints will be stored.\n",
      "  warnings.warn(\n",
      "Epoch 0: 100%|██████████| 191/191 [00:08<00:00, 22.21batch/s, train/train_loss_1=0.06329722, train/train_loss_2=0.07011371, train/train_loss_3=0.101814255]   \n",
      "/tmp/ipykernel_5475/4129963786.py:17: DeprecationWarning: Argument `data` is deprecated. Use `data_module` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cfnet = CounterNet()\n",
    "cfnet.train(dm, epochs=1)\n",
    "# Test cases for checking if ParametricCFModule is trained twice.\n",
    "# If it is trained twice, cfs will be different.\n",
    "cfs = jax.vmap(cfnet.generate_cf)(dm.xs)\n",
    "assert cfnet.is_trained == True\n",
    "exp = generate_cf_explanations(cfnet, dm)\n",
    "assert np.allclose(einops.rearrange(exp.cfs, 'N 1 K -> N K'), cfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# dm = load_data(\"dummy\")\n",
    "# ml_model = load_ml_module(\"dummy\")\n",
    "\n",
    "# for cf_module in [CounterNet, CCHVAE, VAECF, L2C, ProtoCF, CLUE]:\n",
    "#     m = cf_module()\n",
    "#     assert m.is_trained == False\n",
    "#     m.train(dm, pred_fn=ml_model.pred_fn, epochs=1)\n",
    "#     assert m.is_trained == True\n",
    "#     exp = generate_cf_explanations(m, dm, pred_fn=ml_model.pred_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
